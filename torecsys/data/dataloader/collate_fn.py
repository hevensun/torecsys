from io import BytesIO
from PIL import Image
import os
import requests
import torch
import torch.nn.utils.rnn as rnn_utils
import torchvision
import torchvision.transforms as transforms
from Typing import Dict, List, Tuple


__field_type__ = ["values", "single_index", "list_index", "sequence_index", "image_dir", "image_url", "sentence"]


def trs_collate_fn(batch_data  : List[list],
                   field_names : List[str],
                   field_types : List[str],
                   **kwargs) -> Dict[str, Tuple[torch.Tensor]]:
    r"""a function for torch.utils.data.DataLoader to collate torch.utils.data.Dataset, 
        which is a list of lists of features in a field for each sample, to a dictionary 
        where the key is field name, and the value is a tuple of torch.Tensor.
    
    Args:
        batch_data (List[list]): batch data generated by torch.utils.data.DataLoader
        field_names (List[str]): name of the elements (i.e. features) in batch data
        field_types (List[str]): type of the elements (i.e. features) in batch data
    
    kwargs:
        image_rootdir (Dict[str, str]): root directory of image fields, key = field name, value = string of root directory
        image_rooturl (Dict[str, str]): root url of image fields, key = field name, value = string of root url
        image_transforms (Dict[str, torchvision.transforms.*]): torchvision.transforms function of image fields, key = field name, value = torchvision.transforms 's function
        sentence_fields (Dict[str, torecsys.data.data.loader.fields.SentenceField]): sentence field to indexing the string sentence, key = fielf name, value = SentenceField
    
    Returns:
        Dict[str, Tuple[torch.Tensor]]: batch data input for embedding layer, key = field name, value = tuple of torch.Tensor
    """
    
    outputs = dict()
    for idx, (field_name, field_type) in enumerate(zip(field_names, field_types)):
        column_data = [d[idx] for d in batch_data]
        
        if field_type == "values":
            outputs[field_name] = (torch.Tensor(column_data), )

        if field_type == "single_index":
            outputs[field_name] = (torch.Tensor(column_data).long(), )
        
        elif field_type == "list_index":
            # to get the descending sorted list and their perm index
            perm_tuple = [(c, s) for c, s in sorted(zip(column_data, range(len(column_data))), key=lambda x: len(x[0]), reverse=True)]

            # to convert lists in the list to tensor for rnn_utils.pad_sequence
            perm_tensors = [torch.Tensor(v[0]) for v in perm_tuple]
            perm_idx = [v[1] for v in perm_tuple]

            # pad the list of tensors
            pad_tensors = rnn_utils.pad_sequence(perm_tensors, batch_first=True, padding_value=0)

            # to get the desort index
            desort_idx = list(sorted(range(len(perm_idx)), key=perm_idx.__getitem__))
            desort_tensors = pad_tensors[desort_idx].long()

            # save desort_tensors to outputs dictionary
            outputs[field_name] = (desort_tensors, )

        elif field_type == "sequence_index":
            # to get the descending sorted list and their perm index
            perm_tuple = [(c, s) for c, s in sorted(zip(column_data, range(len(column_data))), key=lambda x: len(x[0]), reverse=True)]

            # to convert lists in the list to tensor for rnn_utils.pad_sequence
            perm_tensors = [torch.Tensor(v[0]) for v in perm_tuple]
            perm_lengths = torch.Tensor([len(sq) for sq in perm_tensors])
            perm_idx = [v[1] for v in perm_tuple]

            # pad the list of tensors
            pad_tensors = rnn_utils.pad_sequence(perm_tensors, batch_first=True, padding_value=0)

            # to get the desort index
            desort_idx = list(sorted(range(len(perm_idx)), key=perm_idx.__getitem__))
            desort_tensors = pad_tensors[desort_idx].long()
            desort_lengths = perm_lengths[desort_idx].long()

            # save desort_tensors to outputs dictionary
            outputs[field_name] = (desort_tensors, desort_lengths, )
        
        elif field_type == "image_dir":
            # get root dir from kwargs
            root_dir = kwargs.get("image_rootdir", {}).get(field_name, os.getcwd())

            # get transform
            img_transforms = kwargs.get("image_transforms", {}).get(field_name, transforms.ToTensor())
            
            # join root directory with file path
            img_files = [os.path.join(root_dir, img_path[0]) for img_path in column_data]

            # read image with skimage.io
            img_files = [Image.open(img_file) for img_file in img_files]

            # apply transform with torch.transforms and stack them into a tensor
            img_tensors = [img_transforms(img_file) for img_file in img_files]
            img_tensors = torch.stack(img_tensors)

            # save to outputs dictionary where the shape = (batch size, dimensionality of color, height, width)
            outputs[field_name] = (img_tensors, )
        
        elif field_type == "image_url":
            # get root url from kwargs
            root_url = kwargs.get("image_rooturl", {}).get(field_name, "")

            # get transform
            img_transforms = kwargs.get("image_transforms", {}).get(field_name, transforms.ToTensor())

            # join root url with file path
            img_urls = [root_url + img_url[0] for img_url in column_data]
            
            # read image with skimage.io
            img_files = [Image.open(BytesIO(requests.get(img_url).content)) for img_url in img_urls]
            
            # apply transform with torch.transforms and stack them into a tensor
            img_tensors = [img_transforms(img_file) for img_file in img_files]
            img_tensors = torch.stack(img_tensors)

            # save to outputs dictionary where the shape = (batch size, dimensionality of color, height, width)
            outputs[field_name] = (img_tensors, )
        
        elif field_type == "sentence":
            # get vocab field which is initialized
            sentence_field = kwargs.get("sentence_fields", {}).get(fieldname)

            # apply sentence_field.to_index
            sent_tensors, sent_lengths = sentence_field.to_index(column_data)

            # save to outputs dictionary
            outputs[field_name] = (sent_tensors, sent_lengths, )
        
        else:
            # skip if the field_type is not exist
            continue
    
    return outputs
