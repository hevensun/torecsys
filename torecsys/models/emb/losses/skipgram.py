from .functional import skip_gram_loss
import torch
import torch.nn as nn
import torch.nn.functional as F


class SkipGramLoss(nn.Module):
    r"""SkipGramLoss is a module to calculate the loss used in SkipGram algorithm which is
    to calculate the loss by the following formula:
    :math:`loss = - \sum_{c=1}^{C} u_{j_{c}^{*}} + C log ( \sum_{j'=1}^{v} e^{u_{j'}} )` .
    
    :Reference:

    #. `Tomas Mikolov et al, 2013. Efficient Estimation of Word Representations in Vector Space <https://arxiv.org/abs/1301.3781>`_.
    
    """
    def __init__(self):
        r"""
        """
        super(SkipGram, self).__init__()
    
    def forward(self, 
                content_inputs: torch.Tensor, 
                pos_inputs    : torch.Tensor, 
                neg_inputs    : torch.Tensor) -> torch.Tensor:
        r"""feed forward to calculate the loss in skipgram algorithm
        
        Args:
            content_inputs (torch.Tensor), shape = (batch size, 1, embed size), dtype = torch.float: content or anchor to be learnt with samples
            pos_inputs (torch.Tensor), shape = (batch size, 1, embed size), dtype = torch.float: positive samples from dataset
            neg_inputs (torch.Tensor), shape = (batch size, number of negative samples, embed size), dtype = torch.float: negative samples generated by negative sampler
        
        Returns:
            torch.Tensor, shape = (1, ), dtype = torch.float: loss of skipgram algorithm
        """
        loss = skip_gram_loss(content_inputs, pos_inputs, neg_inputs)
        return loss
