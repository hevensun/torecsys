{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer of Field-aware Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchtext\n",
    "import torecsys as trs\n",
    "from typing import Dict, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples data from movielens as a example\n",
    "# trs.data.sampledata.download_ml_data(size=\"latest-small\", dir=\"./data\")\n",
    "_, movies_df, ratings_df, _ = trs.data.sampledata.load_ml_data(size=\"latest-small\", dir=\"./data\")\n",
    "# movies_df[\"year\"] = movies_df.title.apply(lambda x: re.findall(r\"\\((\\d+)\\)\", x))\n",
    "# movies_df[\"year\"] = movies_df.year.apply(lambda x: int(x[0]) if len(x) > 0 else np.nan)\n",
    "# movies_df = pd.concat([\n",
    "#     movies_df, \n",
    "#     pd.get_dummies(movies_df.genres.apply(\n",
    "#         lambda x: x.split(\"|\")).apply(pd.Series).stack()).sum(level=0)\n",
    "# ], axis=1).drop([\"title\", \"genres\"], axis=1)\n",
    "# merged = pd.merge(ratings_df, movies_df, on=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper-parameters of model\n",
    "user_size = ratings_df.userId.max() + 1\n",
    "item_size = ratings_df.movieId.max() + 1\n",
    "\n",
    "embed_size = 16\n",
    "num_fields = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training set and testing set\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs' schema and colleat_fn for dataloader\n",
    "schema = {\n",
    "    \"userId\": [\"user_id\", \"single_index\"],\n",
    "    \"movieId\": [\"movie_id\", \"single_index\"],\n",
    "    \"rating\": [\"labels\", \"values\"]\n",
    "}\n",
    "collate_fn = partial(trs.data.dataloader.dict_collate_fn, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training and testing dataset\n",
    "columns = [\"userId\", \"movieId\", \"rating\"]\n",
    "train_set = trs.data.dataset.DataFrameToDataset(train_df, columns=columns)\n",
    "test_set = trs.data.dataset.DataFrameToDataset(test_df, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training and testing dataloader\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=1024, shuffle=True, \n",
    "    num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=1024, shuffle=False, \n",
    "    num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inititalize embedding fields\n",
    "feat_inputs_embedding = trs.inputs.base.MultiIndicesEmbedding(\n",
    "    1, [user_size, item_size]\n",
    ")\n",
    "field_aware_embedding = trs.inputs.base.MultiIndicesFieldAwareEmbedding(\n",
    "    embed_size, [user_size, item_size]\n",
    ")\n",
    "\n",
    "# define schema of wrapper and initialize InputsWrapper\n",
    "schema = {\n",
    "    \"feat_inputs\"      : (feat_inputs_embedding, [\"user_id\", \"movie_id\"]),\n",
    "    \"field_emb_inputs\" : (field_aware_embedding, [\"user_id\", \"movie_id\"])\n",
    "}\n",
    "\n",
    "# initialize inputs wrapper\n",
    "inputs_wrapper = trs.inputs.InputsWrapper(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize field-aware factorizatiob machine model\n",
    "ffm = trs.models.FieldAwareFactorizationMachineModel(embed_size, num_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize trainer to train the module\n",
    "trainer = trs.Trainer(\n",
    "    inputs_wrapper = inputs_wrapper, \n",
    "    model = ffm,\n",
    "    epochs = 1,\n",
    "    verboses = 1,\n",
    "    use_jit = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_dl:\n",
    "    print(trainer.predict(batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
