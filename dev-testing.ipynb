{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Field-aware Factorization Machine with trs.Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchtext\n",
    "import torecsys as trs\n",
    "from typing import Dict, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples data from movielens as a example\n",
    "# trs.data.sampledata.download_ml_data(size=\"latest-small\")\n",
    "_, movies_df, ratings_df, _ = trs.data.sampledata.load_ml_data(size=\"latest-small\")\n",
    "# movies_df[\"year\"] = movies_df.title.apply(lambda x: re.findall(r\"\\((\\d+)\\)\", x))\n",
    "# movies_df[\"year\"] = movies_df.year.apply(lambda x: int(x[0]) if len(x) > 0 else np.nan)\n",
    "# movies_df = pd.concat([\n",
    "#     movies_df, \n",
    "#     pd.get_dummies(movies_df.genres.apply(\n",
    "#         lambda x: x.split(\"|\")).apply(pd.Series).stack()).sum(level=0)\n",
    "# ], axis=1).drop([\"title\", \"genres\"], axis=1)\n",
    "# merged = pd.merge(ratings_df, movies_df, on=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_size = ratings_df.userId.max() + 1\n",
    "item_size = ratings_df.movieId.max() + 1\n",
    "\n",
    "embed_size = 16\n",
    "num_fields = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = trs.data.dataset.DataFrameToDataset(ratings_df, columns=[\"userId\", \"movieId\", \"rating\"])\n",
    "schema = {\n",
    "    \"userId\": [\"user_id\", \"single_index\"],\n",
    "    \"movieId\": [\"movie_id\", \"single_index\"],\n",
    "    \"rating\": [\"labels\", \"values\"]\n",
    "}\n",
    "collate_fn = partial(trs.data.dataloader.dict_collate_fn, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\torecsys\\torecsys\\utils\\decorator\\decorator.py:49: UserWarning: the module have been checked with torch.jit.trace, but the feature is in experimemtal.!!! Remark. It is not allow to use dropout at this stage, since inferences of the same inputs will be different after dropout layer. So, Please use dropout_p = 0.0 or None.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# inititalize embedding fields\n",
    "feat_inputs_embedding = trs.inputs.base.MultipleIndexEmbedding(\n",
    "    1, [user_size, item_size]\n",
    ")\n",
    "field_aware_embedding = trs.inputs.base.FieldAwareMultipleIndexEmbedding(\n",
    "    embed_size, [user_size, item_size]\n",
    ")\n",
    "\n",
    "# define schema of wrapper and initialize InputsWrapper\n",
    "schema = {\n",
    "    \"feat_inputs\"      : (feat_inputs_embedding, [\"user_id\", \"movie_id\"]),\n",
    "    \"field_emb_inputs\" : (field_aware_embedding, [\"user_id\", \"movie_id\"])\n",
    "}\n",
    "inputs_wrapper = trs.inputs.InputsWrapper(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize field-aware factorizatiob machine model\n",
    "ffm = trs.models.FieldAwareFactorizationMachineModel(embed_size, num_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger have been initialized.\n",
      "tensorboard summary writter have been created and the log directory is set to C:\\Users\\User\\Desktop\\torecsys\\torecsys\\utils\\training\\logdir.\n",
      "+------------------------------------------------------------------------------+\n",
      "|     Name:                                  Value:                            |\n",
      "| Embeddings      InputsWrapper                                                |\n",
      "| Model           FieldAwareFactorizationMachineModel                          |\n",
      "| Loss            MSELoss                                                      |\n",
      "| Optimizer       AdamW                                                        |\n",
      "| Reg norm        2                                                            |\n",
      "| Reg lambda      0.100                                                        |\n",
      "| Num of epochs   10                                                           |\n",
      "| Log directory   C:\\Users\\User\\Desktop\\torecsys\\torecsys\\utils\\training\\logdi |\n",
      "|                 r                                                            |\n",
      "+------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "trainer = trs.Trainer(\n",
    "    inputs_wrapper = inputs_wrapper, \n",
    "    model = ffm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebeef499475486c988b8db8ce7abc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='step loss : ??.????', layout=Layout(flex='2'), max=12605, styâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step avg loss : 0.1184\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = torch.jit.trace(trs.inputs.base.EmbeddingDict([\"userId\", \"itemId\"], [\"single_index\", \"single_index\"], [100, 50], [16, 16]), {\"userId\": (torch.Tensor([[1]]).long()), \"itemId\": (torch.Tensor([[1]]).long())})\n",
    "emb_dict({\"userId\": (torch.Tensor([[1]]).long()), \"itemId\": (torch.Tensor([[1]]).long())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_emb = torch.jit.trace(trs.inputs.base.FieldAwareMultipleIndexEmbedding(16, [100, 10]), torch.Tensor([[1, 1]]).long())\n",
    "fa_emb(torch.Tensor([[1, 1]]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_emb = torch.jit.trace(trs.inputs.base.ListIndexEmbedding(16, 100, num_heads=4), torch.Tensor([[1, 4, 5]]).long())\n",
    "list_emb(torch.Tensor([[1, 4, 5]]).long())\n",
    "# try to fix if use trace\n",
    "# list_emb.show_attention(torch.Tensor([[1, 4, 5]]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_emb = torch.jit.trace(trs.inputs.base.MultipleIndexEmbedding(16, [100, 10]), torch.Tensor([[1, 1]]).long())\n",
    "mlp_emb(torch.Tensor([[1, 1]]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_emb = torch.jit.trace(trs.inputs.base.SequenceIndexEmbedding(16, 100), (torch.Tensor([[3, 1, 0], [4, 2, 5]]).long(), torch.Tensor([2, 3]).long()))\n",
    "sq_emb(torch.Tensor([[3, 1, 0], [4, 2, 5]]).long(), torch.Tensor([2, 3]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_emb = torch.jit.trace(trs.inputs.base.SingleIndexEmbedding(16, 100), torch.Tensor([[1]]).long())\n",
    "index_emb(torch.Tensor([[1]]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = torch.jit.trace(trs.inputs.base.StackedInputs([\"userId\", \"itemId\"], [\"single_index\", \"single_index\"], [100, 50], [16, 16]), ({\"userId\": (torch.Tensor([[1]]).long()), \"itemId\": (torch.Tensor([[1]]).long())}))\n",
    "stack({\"userId\": (torch.Tensor([[1]]).long()), \"itemId\": (torch.Tensor([[1]]).long())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = torch.jit.trace(trs.inputs.base.ValueInputs(5), torch.randn(size=(1, 5)))\n",
    "val(torch.randn(size=(1, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = torch.jit.trace(trs.inputs.base.ImageInputs(16, 3, [8, 8], [1, 1], [1, 1], [1, 1]), torch.randn(4, 3, 64, 64))\n",
    "img_inputs(torch.randn(4, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_img = torch.jit.trace(trs.inputs.base.PretrainedImageInputs(16, \"resnet18\"), torch.randn(4, 3, 64, 64))\n",
    "pre_img(torch.randn(4, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"sequenceId\"     : torch.randint(100, size=(8, 4)),\n",
    "    \"sequenceLength\" : torch.Tensor([4] * 8),\n",
    "    \"values\"         : torch.randn(size=(8, 8)),\n",
    "    \"userId\"         : torch.randint(100, size=(8, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_schema = [\n",
    "    (trs.inputs.base.SequenceIndexEmbedding(8, 100), [\"sequenceId\"], [\"sequenceLength\"]),\n",
    "    (trs.inputs.base.ValueInputs(8), [\"values\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_schema = [\n",
    "    (trs.inputs.base.SingleIndexEmbedding(16, 100), [\"userId\"]), \n",
    "    (trs.inputs.base.ConcatInputs(cat_schema), [\"sequenceId\", \"sequenceLength\", \"values\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = trs.inputs.base.StackedInputs(stacked_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_schema = {\n",
    "    \"stacked\": (trs.inputs.base.StackedInputs(stacked_schema), [\"userId\", \"sequenceId\", \"sequenceLength\", \"values\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped = trs.inputs.InputsWrapper(wrapped_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 8\n",
    "n = 5\n",
    "b = 16\n",
    "\n",
    "feat_inputs = torch.randn(size=(b, n, 1))\n",
    "field_emb = torch.randn(size=(b, n, e))\n",
    "field_aware_emb = torch.randn(size=(b, n * n, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_emb = torch.randn(size=(b, 2, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_model = torch.jit.trace(trs.models.AttentionalFactorizationMachineModel(e, n, 8, 0.0), (feat_inputs, field_emb))\n",
    "afm_model(feat_inputs, field_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_model = torch.jit.trace(trs.models.DeepAndCrossNetworkModel(e * n, 1, [10], 2, 1, [0.0], nn.ReLU6()), field_emb)\n",
    "dc_model(field_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffm_model = torch.jit.trace(trs.models.DeepFieldAwareFactorizationMachineModel(e, n, 1, [10], 0.0, [0.0], nn.Tanh(), 1), field_aware_emb)\n",
    "dffm_model(field_aware_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_model = torch.jit.trace(trs.models.DeepFactorizationMachineModel(e, n, [10], 0.0, [0.0], nn.ReLU(), 1), (feat_inputs, field_emb))\n",
    "dfm_model(feat_inputs, field_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = torch.jit.trace(trs.models.FactorizationMachineModel(e, n, 0.1), (feat_inputs, field_emb))\n",
    "fm(feat_inputs, field_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnn = torch.jit.trace(trs.models.FactorizationMachineSupportedNeuralNetwork(e, n, 1, [10], 0.1, [0.1], nn.Tanh()), (feat_inputs, field_emb))\n",
    "fmnn(feat_inputs, field_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatdffm = torch.jit.trace(trs.models.FieldAttentiveDeepFieldAwareFactorizationMachineModel(e, n, 10, [10], 16, 0.0, [0.1], nn.Tanh()), field_aware_emb)\n",
    "fatdffm(field_aware_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffm = torch.jit.trace(trs.models.FieldAwareFactorizationMachineModel(e, n), (feat_inputs, field_aware_emb))\n",
    "ffm(feat_inputs, field_aware_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = torch.jit.trace(trs.models.LogisticRegressionModel(n), feat_inputs)\n",
    "lr(feat_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf = torch.jit.trace(trs.models.NeuralCollaborativeFilteringModel(e, 1, [10], [0.1], nn.ReLU6()), user_item_emb)\n",
    "ncf(user_item_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afm = trs.layers.AttentionalFactorizationMachineLayer(e, n, attn_size=8, dropout_p=0.0)\n",
    "print(afm(field_emb)[0].size())\n",
    "print(afm(field_emb)[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blin = trs.layers.BilinearNetworkLayer(e, n, 1, 3)\n",
    "blin(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen = trs.layers.ComposeExcitationNetworkLayer(n)\n",
    "cen(field_aware_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cin = trs.layers.CompressInteractionNetworkLayer(e, n, 1, [10, 10, 10])\n",
    "cin(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = trs.layers.CrossNetworkLayer(5, e, n)\n",
    "cross(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = trs.layers.FactorizationMachineLayer(0.0)\n",
    "fm(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffm = trs.layers.FieldAwareFactorizationMachineLayer(n, 0.0)\n",
    "ffm(field_aware_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = trs.layers.InnerProductNetworkLayer(n)\n",
    "inner(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = trs.layers.MultilayerPerceptronLayer(1, [10, 10, 10], embed_size=e, num_fields=n, dropout_p=[0.0, 0.0, 0.0])\n",
    "mlp(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer = trs.layers.OuterProductNetworkLayer(e, n)\n",
    "outer(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = trs.layers.WideLayer(e, n, 1)\n",
    "wide(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
