{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Field-aware Factorization Machine with trs.Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchtext\n",
    "import torecsys as trs\n",
    "from typing import Dict, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples data from movielens as a example\n",
    "# trs.data.sampledata.download_ml_data(size=\"latest-small\")\n",
    "_, movies_df, ratings_df, _ = trs.data.sampledata.load_ml_data(size=\"latest-small\")\n",
    "# movies_df[\"year\"] = movies_df.title.apply(lambda x: re.findall(r\"\\((\\d+)\\)\", x))\n",
    "# movies_df[\"year\"] = movies_df.year.apply(lambda x: int(x[0]) if len(x) > 0 else np.nan)\n",
    "# movies_df = pd.concat([\n",
    "#     movies_df, \n",
    "#     pd.get_dummies(movies_df.genres.apply(\n",
    "#         lambda x: x.split(\"|\")).apply(pd.Series).stack()).sum(level=0)\n",
    "# ], axis=1).drop([\"title\", \"genres\"], axis=1)\n",
    "# merged = pd.merge(ratings_df, movies_df, on=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_size = ratings_df.userId.max() + 1\n",
    "item_size = ratings_df.movieId.max() + 1\n",
    "\n",
    "embed_size = 16\n",
    "num_fields = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = trs.data.dataset.DataFrameToDataset(ratings_df, columns=[\"userId\", \"movieId\", \"rating\"])\n",
    "schema = {\n",
    "    \"userId\": [\"user_id\", \"single_index\"],\n",
    "    \"movieId\": [\"movie_id\", \"single_index\"],\n",
    "    \"rating\": [\"labels\", \"values\"]\n",
    "}\n",
    "collate_fn = partial(trs.data.dataloader.dict_collate_fn, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\torecsys\\torecsys\\utils\\decorator\\decorator.py:49: UserWarning: the module have been checked with torch.jit.trace, but the feature is in experimemtal.!!! Remark. It is not allow to use dropout at this stage, since inferences of the same inputs will be different after dropout layer. So, Please use dropout_p = 0.0 or None.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# inititalize embedding fields\n",
    "feat_inputs_embedding = trs.inputs.base.MultipleIndexEmbedding(\n",
    "    1, [user_size, item_size]\n",
    ")\n",
    "field_aware_embedding = trs.inputs.base.FieldAwareMultipleIndexEmbedding(\n",
    "    embed_size, [user_size, item_size]\n",
    ")\n",
    "\n",
    "# define schema of wrapper and initialize InputsWrapper\n",
    "schema = {\n",
    "    \"feat_inputs\"      : (feat_inputs_embedding, [\"user_id\", \"movie_id\"]),\n",
    "    \"field_emb_inputs\" : (field_aware_embedding, [\"user_id\", \"movie_id\"])\n",
    "}\n",
    "inputs_wrapper = trs.inputs.InputsWrapper(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_inputs_embedding_1 = trs.inputs.base.MultipleIndexEmbedding(\n",
    "    1, [user_size, item_size]\n",
    ")\n",
    "feat_inputs_embedding_2 = trs.inputs.base.MultipleIndexEmbedding(\n",
    "    1, [user_size, item_size]\n",
    ")\n",
    "schema = [(feat_inputs_embedding_1, [\"user_id\", \"movie_id\"]), (feat_inputs_embedding_2, [\"user_id\", \"movie_id\"])]\n",
    "concat_inputs = trs.inputs.base.ConcatInputs(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TracedModule[ConcatInputs](\n",
       "  (embedding_0): TracedModule[MultipleIndexEmbedding](\n",
       "    (embedding): TracedModule[Embedding]()\n",
       "  )\n",
       "  (embedding_1): TracedModule[MultipleIndexEmbedding](\n",
       "    (embedding): TracedModule[Embedding]()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.jit.trace(concat_inputs, {\"user_id\": torch.randint(10, size=(8, 1)).long(), \"movie_id\": torch.randint(10, size=(8, 1)).long()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize field-aware factorizatiob machine model\n",
    "ffm = trs.models.FieldAwareFactorizationMachineModel(embed_size, num_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feat_inputs.embedding.weight': Parameter containing:\n",
       " tensor([[-0.8162],\n",
       "         [-0.3292],\n",
       "         [ 0.4122],\n",
       "         ...,\n",
       "         [ 0.3097],\n",
       "         [ 0.1494],\n",
       "         [-0.8151]], requires_grad=True),\n",
       " 'field_emb_inputs.embeddings.0.weight': Parameter containing:\n",
       " tensor([[-0.0023, -0.0020,  0.0019,  ..., -0.0016, -0.0037, -0.0031],\n",
       "         [-0.0014,  0.0010,  0.0018,  ..., -0.0029,  0.0025,  0.0021],\n",
       "         [-0.0054,  0.0029,  0.0038,  ..., -0.0024,  0.0054, -0.0021],\n",
       "         ...,\n",
       "         [ 0.0041, -0.0029,  0.0044,  ...,  0.0023, -0.0046,  0.0046],\n",
       "         [-0.0020,  0.0009, -0.0020,  ...,  0.0029,  0.0022, -0.0028],\n",
       "         [ 0.0027, -0.0039,  0.0026,  ..., -0.0014, -0.0028,  0.0039]],\n",
       "        requires_grad=True),\n",
       " 'field_emb_inputs.embeddings.1.weight': Parameter containing:\n",
       " tensor([[ 0.0034, -0.0055,  0.0041,  ...,  0.0015,  0.0024,  0.0031],\n",
       "         [ 0.0022,  0.0055, -0.0031,  ...,  0.0010,  0.0052,  0.0035],\n",
       "         [-0.0038,  0.0044,  0.0035,  ..., -0.0032, -0.0012,  0.0014],\n",
       "         ...,\n",
       "         [ 0.0024,  0.0049,  0.0049,  ..., -0.0031,  0.0030,  0.0053],\n",
       "         [ 0.0012, -0.0011, -0.0048,  ..., -0.0012,  0.0018, -0.0026],\n",
       "         [ 0.0044,  0.0055, -0.0009,  ..., -0.0035, -0.0021, -0.0049]],\n",
       "        requires_grad=True)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(inputs_wrapper.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = torch.utils.tensorboard.SummaryWriter(log_dir=\"logdir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self : ClassType<FieldAwareFactorizationMachineModel>,\n",
      "      %feat_inputs : Float(8, 2, 1),\n",
      "      %field_emb_inputs : Float(8, 4, 16)):\n",
      "  %1 : Tensor = prim::GetAttr[name=\"bias\"](%self)\n",
      "  %6 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:51:0\n",
      "  %7 : int[] = prim::ListConstruct(%6), scope: FieldAwareFactorizationMachineModel\n",
      "  %8 : bool = prim::Constant[value=0](), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:51:0\n",
      "  %9 : int? = prim::Constant(), scope: FieldAwareFactorizationMachineModel\n",
      "  %ffm_first : Float(8, 1) = aten::sum(%feat_inputs, %7, %8, %9), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:51:0\n",
      "  %11 : int = prim::Constant[value=2](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:39:0\n",
      "  %12 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:39:0\n",
      "  %13 : Tensor[] = aten::chunk(%field_emb_inputs, %11, %12), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:39:0\n",
      "  %14 : Float(8!, 2, 16), %15 : Float(8!, 2, 16) = prim::ListUnpack(%13), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm]\n",
      "  %16 : int = prim::Constant[value=0](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %17 : int = prim::Constant[value=0](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %18 : int = prim::Constant[value=9223372036854775807](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %19 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %20 : Float(8!, 2, 16) = aten::slice(%15, %16, %17, %18, %19), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %21 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %22 : int = prim::Constant[value=0](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %23 : Float(8!, 16) = aten::select(%20, %21, %22), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %24 : int = prim::Constant[value=0](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %25 : int = prim::Constant[value=0](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %26 : int = prim::Constant[value=9223372036854775807](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %27 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %28 : Float(8!, 2, 16) = aten::slice(%14, %24, %25, %26, %27), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %29 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %30 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %31 : Float(8!, 16) = aten::select(%28, %29, %30), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %32 : Float(8, 16) = aten::mul(%23, %31), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:45:0\n",
      "  %33 : Tensor[] = prim::ListConstruct(%32), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm]\n",
      "  %34 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:48:0\n",
      "  %input : Float(8, 1, 16) = aten::stack(%33, %34), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm] # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\layers\\ctr\\field_aware_factorization_machine.py:48:0\n",
      "  %36 : float = prim::Constant[value=0](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm]/Dropout[dropout] # c:\\program files\\python37\\lib\\site-packages\\torch\\nn\\functional.py:806:0\n",
      "  %37 : bool = prim::Constant[value=0](), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm]/Dropout[dropout] # c:\\program files\\python37\\lib\\site-packages\\torch\\nn\\functional.py:806:0\n",
      "  %ffm_second.1 : Float(8, 1, 16) = aten::dropout(%input, %36, %37), scope: FieldAwareFactorizationMachineModel/FieldAwareFactorizationMachineLayer[ffm]/Dropout[dropout] # c:\\program files\\python37\\lib\\site-packages\\torch\\nn\\functional.py:806:0\n",
      "  %39 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:58:0\n",
      "  %40 : int = prim::Constant[value=2](), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:58:0\n",
      "  %41 : int[] = prim::ListConstruct(%39, %40), scope: FieldAwareFactorizationMachineModel\n",
      "  %42 : bool = prim::Constant[value=0](), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:58:0\n",
      "  %43 : int? = prim::Constant(), scope: FieldAwareFactorizationMachineModel\n",
      "  %44 : Float(8) = aten::sum(%ffm_second.1, %41, %42, %43), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:58:0\n",
      "  %45 : int = prim::Constant[value=-1](), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:58:0\n",
      "  %ffm_second : Float(8, 1) = aten::unsqueeze(%44, %45), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:58:0\n",
      "  %47 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:61:0\n",
      "  %48 : Float(8, 1) = aten::add(%ffm_second, %ffm_first, %47), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:61:0\n",
      "  %49 : int = prim::Constant[value=1](), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:61:0\n",
      "  %50 : Float(8, 1) = aten::add(%48, %1, %49), scope: FieldAwareFactorizationMachineModel # C:\\Users\\User\\Desktop\\torecsys\\torecsys\\models\\ctr\\field_aware_factorization_machine.py:61:0\n",
      "  return (%50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in dataloader:\n",
    "    labels = b.pop(\"labels\")\n",
    "    x = inputs_wrapper(b)\n",
    "    writer.add_graph(ffm, tuple(x.values()), verbose=True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trs.Trainer(\n",
    "    inputs_wrapper = inputs_wrapper, \n",
    "    model = ffm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = torch.jit.trace(trs.inputs.base.EmbeddingDict([\"userId\", \"itemId\"], [\"single_index\", \"single_index\"], [100, 50], [16, 16]), {\"userId\": (torch.Tensor([[1]]).long()), \"itemId\": (torch.Tensor([[1]]).long())})\n",
    "emb_dict({\"userId\": (torch.Tensor([[1]]).long()), \"itemId\": (torch.Tensor([[1]]).long())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_emb = torch.jit.trace(trs.inputs.base.FieldAwareMultipleIndexEmbedding(16, [100, 10]), torch.Tensor([[1, 1]]).long())\n",
    "fa_emb(torch.Tensor([[1, 1]]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_emb = torch.jit.trace(trs.inputs.base.ListIndexEmbedding(16, 100, num_heads=4), torch.Tensor([[1, 4, 5]]).long())\n",
    "list_emb(torch.Tensor([[1, 4, 5]]).long())\n",
    "# try to fix if use trace\n",
    "# list_emb.show_attention(torch.Tensor([[1, 4, 5]]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_emb = torch.jit.trace(trs.inputs.base.MultipleIndexEmbedding(16, [100, 10]), torch.Tensor([[1, 1]]).long())\n",
    "mlp_emb(torch.Tensor([[1, 1]]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_emb = torch.jit.trace(trs.inputs.base.SequenceIndexEmbedding(16, 100), (torch.Tensor([[3, 1, 0], [4, 2, 5]]).long(), torch.Tensor([2, 3]).long()))\n",
    "sq_emb(torch.Tensor([[3, 1, 0], [4, 2, 5]]).long(), torch.Tensor([2, 3]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_emb = torch.jit.trace(trs.inputs.base.SingleIndexEmbedding(16, 100), torch.Tensor([[1]]).long())\n",
    "index_emb(torch.Tensor([[1]]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = torch.jit.trace(trs.inputs.base.StackedInputs([\"userId\", \"itemId\"], [\"single_index\", \"single_index\"], [100, 50], [16, 16]), ({\"userId\": (torch.Tensor([[1]]).long()), \"itemId\": (torch.Tensor([[1]]).long())}))\n",
    "stack({\"userId\": (torch.Tensor([[1]]).long()), \"itemId\": (torch.Tensor([[1]]).long())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = torch.jit.trace(trs.inputs.base.ValueInputs(5), torch.randn(size=(1, 5)))\n",
    "val(torch.randn(size=(1, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = torch.jit.trace(trs.inputs.base.ImageInputs(16, 3, [8, 8], [1, 1], [1, 1], [1, 1]), torch.randn(4, 3, 64, 64))\n",
    "img_inputs(torch.randn(4, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_img = torch.jit.trace(trs.inputs.base.PretrainedImageInputs(16, \"resnet18\"), torch.randn(4, 3, 64, 64))\n",
    "pre_img(torch.randn(4, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"sequenceId\"     : torch.randint(100, size=(8, 4)),\n",
    "    \"sequenceLength\" : torch.Tensor([4] * 8),\n",
    "    \"values\"         : torch.randn(size=(8, 8)),\n",
    "    \"userId\"         : torch.randint(100, size=(8, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_schema = [\n",
    "    (trs.inputs.base.SequenceIndexEmbedding(8, 100), [\"sequenceId\"], [\"sequenceLength\"]),\n",
    "    (trs.inputs.base.ValueInputs(8), [\"values\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_schema = [\n",
    "    (trs.inputs.base.SingleIndexEmbedding(16, 100), [\"userId\"]), \n",
    "    (trs.inputs.base.ConcatInputs(cat_schema), [\"sequenceId\", \"sequenceLength\", \"values\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = trs.inputs.base.StackedInputs(stacked_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_schema = {\n",
    "    \"stacked\": (trs.inputs.base.StackedInputs(stacked_schema), [\"userId\", \"sequenceId\", \"sequenceLength\", \"values\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped = trs.inputs.InputsWrapper(wrapped_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 8\n",
    "n = 5\n",
    "b = 16\n",
    "\n",
    "feat_inputs = torch.randn(size=(b, n, 1))\n",
    "field_emb = torch.randn(size=(b, n, e))\n",
    "field_aware_emb = torch.randn(size=(b, n * n, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_emb = torch.randn(size=(b, 2, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_model = torch.jit.trace(trs.models.AttentionalFactorizationMachineModel(e, n, 8, 0.0), (feat_inputs, field_emb))\n",
    "afm_model(feat_inputs, field_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_model = torch.jit.trace(trs.models.DeepAndCrossNetworkModel(e * n, 1, [10], 2, 1, [0.0], nn.ReLU6()), field_emb)\n",
    "dc_model(field_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffm_model = torch.jit.trace(trs.models.DeepFieldAwareFactorizationMachineModel(e, n, 1, [10], 0.0, [0.0], nn.Tanh(), 1), field_aware_emb)\n",
    "dffm_model(field_aware_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_model = torch.jit.trace(trs.models.DeepFactorizationMachineModel(e, n, [10], 0.0, [0.0], nn.ReLU(), 1), (feat_inputs, field_emb))\n",
    "dfm_model(feat_inputs, field_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = torch.jit.trace(trs.models.FactorizationMachineModel(e, n, 0.1), (feat_inputs, field_emb))\n",
    "fm(feat_inputs, field_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnn = torch.jit.trace(trs.models.FactorizationMachineSupportedNeuralNetwork(e, n, 1, [10], 0.1, [0.1], nn.Tanh()), (feat_inputs, field_emb))\n",
    "fmnn(feat_inputs, field_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatdffm = torch.jit.trace(trs.models.FieldAttentiveDeepFieldAwareFactorizationMachineModel(e, n, 10, [10], 16, 0.0, [0.1], nn.Tanh()), field_aware_emb)\n",
    "fatdffm(field_aware_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffm = torch.jit.trace(trs.models.FieldAwareFactorizationMachineModel(e, n), (feat_inputs, field_aware_emb))\n",
    "ffm(feat_inputs, field_aware_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = torch.jit.trace(trs.models.LogisticRegressionModel(n), feat_inputs)\n",
    "lr(feat_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf = torch.jit.trace(trs.models.NeuralCollaborativeFilteringModel(e, 1, [10], [0.1], nn.ReLU6()), user_item_emb)\n",
    "ncf(user_item_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afm = trs.layers.AttentionalFactorizationMachineLayer(e, n, attn_size=8, dropout_p=0.0)\n",
    "print(afm(field_emb)[0].size())\n",
    "print(afm(field_emb)[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blin = trs.layers.BilinearNetworkLayer(e, n, 1, 3)\n",
    "blin(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen = trs.layers.ComposeExcitationNetworkLayer(n)\n",
    "cen(field_aware_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cin = trs.layers.CompressInteractionNetworkLayer(e, n, 1, [10, 10, 10])\n",
    "cin(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = trs.layers.CrossNetworkLayer(5, e, n)\n",
    "cross(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = trs.layers.FactorizationMachineLayer(0.0)\n",
    "fm(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffm = trs.layers.FieldAwareFactorizationMachineLayer(n, 0.0)\n",
    "ffm(field_aware_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = trs.layers.InnerProductNetworkLayer(n)\n",
    "inner(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = trs.layers.MultilayerPerceptronLayer(1, [10, 10, 10], embed_size=e, num_fields=n, dropout_p=[0.0, 0.0, 0.0])\n",
    "mlp(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer = trs.layers.OuterProductNetworkLayer(e, n)\n",
    "outer(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = trs.layers.WideLayer(e, n, 1)\n",
    "wide(field_emb).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
